# NeRF —— Neural Radiance Fields

**NeRF**，即用于三维场景重建的深度学习方法。它的主要思想是：通过（唯一）输入**一组具有已知相机姿势的图像**，捕捉场景中每个点的辐射量，训练神经网络，将场景重现为用于视图合成的神经辐射场，从而实现对三维场景的高质量建模。  

**注意**：NeRF 不是直接恢复整个 3D 场景几何形状，而是生成一种称为“辐射场”的体积表示，它能够为相关 3D 空间中的每个点创建**颜色和密度**。

这属于反渲染Inverse Rendering技术。另外，三维重建也是广义上的反渲染，但核心是重建几何，不注重appearance（材质与光线） 。

## 1 结构

首先，进行场景建模：将**静态**场景表示为一个**连续的 5D 函数**，该函数输出空间中每个点 $(x, y, z)$ 在每个方向 $(θ, φ)$ 发射的辐射。然后定义密度：每个点的密度控制在该点通过的光线积累了多少辐射，其作用类似于微分不透明度。

接着，NeRF通过优化一个没有任何卷积层的**深度全连接神经网络**（多层感知器MLP），通过从单个5D坐标 $(x, y, z, θ, φ)$ 回归到单个体积密度和与视图相关的RGB颜色 $(σ, R, G, B)$。

*Volume Rendering：在体积渲染中，每个体素（体积像素）都有一个关联的属性，比如密度、颜色、透明度等。渲染算法通过考虑这些属性以及光线在体积中的传播，生成最终的图像。*

优化过程中，使用体积渲染的技术，沿着光线积累此场景表示的样本，以便从任何视点渲染场景。为了从特定的角度来渲染此神经辐射场 （NeRF），作者：

1. 在场景中移动相机光线以生成一组采样的 3D 点
2. 使用这些点及其相应的 2D 观看方向作为神经网络的输入，以生成一组颜色和密度的输出
3. 使用经典的体积渲染技术将这些颜色和密度累积到 2D 图像中。

由于这个过程是自然可微的，我们可以使用**梯度下降**来优化这个模型，方法是**最小化每个观察到的图像与从我们的表示中渲染的相应视图之间的误差**。在多个视图中最小化此误差可鼓励网络通过为包含真实基础场景内容的位置分配高体积密度和准确的颜色来预测场景的连贯模型。

## 2 神经辐射场场景表示

将一个连续场景表示为 5D 向量值函数，其输入是 3D 位置和 2D 观看方向 $x = (x, y, z) , d = (θ, φ)$，其输出是发射颜色和体积密度 $c = (R, G, B), σ$。

![Alt text](image-1.png)

1. 将方向表示为 3D 笛卡尔单位向量 d
2. 使用 MLP 网络 F Θ ： （x，d） → （c，σ） 近似这种连续的 5D 场景表示，并优化其权重 Θ，以从每个输入 5D 坐标映射到其相应的体积密度和方向发射颜色。 
3. 为使多视图一致，限制网络仅将体积密度σ预测为位置 x 的函数，同时允许将 RGB 颜色 c 预测为位置和观看方向的函数。
4. 神经网络架构：MLP FΘ  首先处理具有 8 个全连接层的输入 3D 坐标 x（使用 ReLU 激活和每层 256 个通道），然后输出 σ 和 256  维特征向量。然后，该特征向量与相机光线的观看方向连接，并传递到一个额外的全连接层（使用 ReLU 激活和 128 个通道），该层输出与视图相关的 RGB 颜色。

## 3 使用辐射场进行体积渲染

5D 神经辐射场将场景表示为空间中**任何点**的**体积密度**和**定向发射辐射**。我们使用经典体积渲染的原理[16]来渲染穿过场景的任何光线的颜色  
 
    Kajiya, J.T., Herzen, B.P.V.: Ray tracing volume densities. Computer Graphics (SIGGRAPH) (1984)



预期颜色 $C(r)$ （积分上下限为 tn 和 tf）的积分形式：

![Alt text](image-2.png)

$σ(x)$: 体积密度，可以解释为光线终止于位置 x 处的无穷小粒子的微分概率。  
$r(t) = o + td$: 相机光线   
$C(r)$：表示在点 r 处的颜色。  
$T(t)$：透射率，表示从路径起始点 tn 到当前点 t 的透射率，通过对路径上的吸收函数 $\sigma(\mathbf{r}(s))σ(r(s))$ 进行积分来计算。即，射线从tn传播到t而不击中任何其他粒子的概率。  
$\sigma(\mathbf{r}(t))$：表示在路径上的点 $\mathbf{r}(t)r(t)$ 处的体积密度（opacity）。  
$\mathbf{c}(\mathbf{r}(t),d)$：表示在路径上的点 $\mathbf{r}(t)$ 处的颜色，其中 $\mathbf{d}$ 是观察方向。  
$t_n$和 $t_f$：表示路径的起始点和终止点


从连续神经辐射场渲染视图需要估算这个积分 $C(r)$，以获得通过所需虚拟摄像机的每个像素追踪的相机光线。

尽管我们使用一组离散的样本来估计积分，但因为分层采样使MLP 在优化过程中在连续位置上被评估，所以仍然能够表示一个连续的场景。我们使用这些样本和 Max [26] 在体积渲染评论中讨论的正交规则来估计 $C(r)$：

![Alt text](image-3.png)

## 4 优化神经辐射场

*上述组件已经将场景和建模篇为神经辐射场，但不能达到最高质量，因而进行优化* —— 输入坐标的位置编码，有助于MLP表示高频函数; 分层采样程序，使我们能够有效地对这种高频表示进行采样.


### 4.1 位置编码  

*位置编码 的名称来源于 Transformer 架构*

研究表明，深度网络偏向于学习低频函数：让网络 FΘ直接对（xyzθφ）输入坐标进行操作会导致渲染在表示颜色和几何的高频变化方面表现不佳。  

在将输入传递到网络之前，使用高频函数将输入映射到更高维度的空间，可以更好地拟合包含高频变化的数据。

$F_{\Theta}=F_{\Theta}^{\prime}\circ\gamma $ 

$\gamma$ 是 $R$ 到更高维 $R^{2L}$ 的映射；$F_{\Theta}^{\prime}$ 并且仍然只是一个常规的 MLP。编码函数如下：

$\gamma(p)=\left(\sin\left(2^0\pi p\right),\cos\left(2^0\pi p\right),\:\cdots,\sin\left(2^{L-1}\pi p\right),\:\cos\left(2^{L-1}\pi p\right)\right)$

### 4.2 分层体积采样

无差别密集采样是低效的，因自由空间和被遮挡区域无需重复采样 —— 可以**通过按比例分配样本对最终渲染的预期效果来提高渲染效率**。

分层，即使用两个网咯来表示场景，同时优化，一个粗略，一个精细。大体步骤如下：  

1. 首先使用分层采样对一组 Nc  位置进行采样，并评估这些位置的“粗略”网络，如方程 2 和 3 中所述。给定这个“粗略”网络的输出。
2. 对每条射线沿线的点进行更明智的采样，其中样本偏向体积的相关部分，即“精细”部分。

以下是详细步骤，这个过程将更多的样本分配给期望包含可见内容的区域：

1. 首先将方程3中来自“粗糙”网络的 alpha 混合颜色 $\hat{C}_c(r)$ 重写为沿着光线采样的所有颜色$c_i$ 的加权和：  
$\hat{C}_c(\mathbf{r})=\sum\limits_{i=1}^{N_c}w_ic_i\:,\quad w_i=T_i(1-\exp(-\sigma_i\delta_i))$

2. 将这些权重归一化为$\hat{w_i}\:=\:w_i\Big/\sum_{j=1}^{N_c}w_j$，这是会在光线上产生分段常数的概率密度函数（PDF）

3. 使用逆变换采样从这个分布中抽取第二组 $N_f$ 个位置

4. 得到细致网络：在所有 $N_c+N_f$ 个样本的基础上，使用 方程3 计算光线的最终渲染颜色 $\hat{C}_f(r)$ 

### 4.3 NeRF流程中的其他细节

为每个场景优化一个神经网络，只需要：一个包含场景的RGB图像、相应的相机姿态、内参数、场景边界数据集。

合成数据可直接用上述参数；真实数据要用COLMAP运动结构包[39]来估计参数。

在每次优化迭代中，作者从数据集中所有像素的集合中随机采样一批相机光线，然后按照第 5.2 节中描述的分层采样，从粗网络查询 Nc 样本，从精细网络查询 Nc + Nf  样本。然后，我们使用第 4 节中描述的体积渲染过程从两组样本中渲染每条光线的颜色。

Loss 为（粗渲染-精渲染）与（精渲染-真实RGB）的总平方误差：  
$\mathcal{L}=\sum_{\mathbf{r}\in\mathcal{R}}\left[\left\|\hat{C}_c(\mathbf{r})-C(\mathbf{r})\right\|_2^2+\left\|\hat{C}_f(\mathbf{r})-C(\mathbf{r})\right\|_2^2\right]$

where $R$ is 光线集合 in each batch, and $C(r)$, $\hat{C}_c(r)$, and $\hat{C}_f(r)$ are the
ground truth, coarse volume predicted, and fine volume predicted RGB colors for ray r respectively.

## 5 总结

### 优点

* 高质量的 3D 重建：NeRF 可以创建复杂场景的高质量 3D 重建，包括精细的表面细节和反射。  
* 视图合成：NeRF 可以从少量输入图像中合成场景的新视图，从而允许从任何视点对场景进行虚拟演练。  
* 连续表示：NeRF 提供场景的连续表示，可以在任何时候有效地查询，从而实现对象操作和渲染等应用程序。  
* 无监督训练：NeRF 可以在无监督的情况下进行训练，这意味着它可以在没有明确监督的情况下学习重建场景。  
* 适用性广：NeRF可应用于广泛的场景，包括室外场景、室内场景，甚至微观结构。


### 缺点

* 训练、渲染慢
* 仅能表示静态场景
* it bakes lighting，失去了动态光的灵活性
* A trained NeRF 无法泛化

